# Детекция токсичных сообщений

## Описание проекта

Проект выполнен в рамках магистерской подготовки. Основная цель проекта — разработка системы для автоматической детекции токсичных сообщений, которая может быть использована для модерации контента в социальных сетях, форумах и других онлайн-платформах.

## Формулировка задачи

Токсичные сообщения, содержащие оскорбления, угрозы или дискриминационные высказывания, представляют серьёзную проблему в цифровой среде. Наша задача — построить модель, способную классифицировать сообщения на токсичные и нетоксичные с высокой точностью. Это поможет автоматизировать процессы модерации и повысить качество онлайн-коммуникаций.

## Данные

В качестве основы были выбраны два датасета с платформы Kaggle:
1.	Датасет 1 — [Russian Language Toxic Comments](https://www.kaggle.com/datasets/blackmoon/russian-language-toxic-comments)

    Источник: Kaggle.
    
    Объём: 14 412 уникальных комментариев, из которых 9 586 — нетоксичных, а 4 826 — токсичных.

2.	Датасет 2 — [Toxic Russian Comments](https://www.kaggle.com/datasets/alexandersemiletov/toxic-russian-comments)
 
    Источник: Kaggle.

    Объём: 248 290 уникальных комментариев, из которых 203 685 — нетоксичных, а 28 567 — токсичных.

Сообщения представлены на русском языке.

Особенности и возможные проблемы:

- токсичные сообщения могут составлять небольшую долю от общего числа, что может потребовать применения методов снижения дисбаланса.
- сложные конструкции, сленг или опечатки могут повлиять на качество предсказаний.

Обоснование выбора:

- Датасет достаточно большой для обучения глубоких моделей.
- Реальная задача и разнообразие примеров повышают применимость модели в различных сценариях.

## Подход к моделированию

Для классификации будет использоваться облегчённая вариация модели BERT - DistilBERT от библиотеки Transformers Hugging Face, которая сохраняет высокую точность предсказаний при меньших вычислительных затратах. Реализация будет выполнена с использованием библиотек PyTorch


