# Детекция токсичных сообщений

## Описание проекта

Проект выполнен в рамках курса MLOps магистерской подготовки. Основная цель проекта — разработка системы для автоматической детекции токсичных сообщений, которая может быть использована для модерации контента в социальных сетях, форумах и других онлайн-платформах.

## Формулировка задачи

Токсичные сообщения, содержащие оскорбления, угрозы или дискриминационные высказывания, представляют серьёзную проблему в цифровой среде. Наша задача — построить модель, способную классифицировать сообщения на токсичные и нетоксичные с высокой точностью. Это поможет автоматизировать процессы модерации и повысить качество онлайн-коммуникаций.

## Данные

Для решения задачи будет использован датасет Jigsaw Toxic Comment Classification Challenge. 

Основные характеристики датасета:

- 159571 уникальных текстовых сообщений с метками.

- Метки состовляют сообщения, размеченные по классам токсичности, включая угрозы, ненависть, оскорбления и пр.

- Сообщения представлены на английском языке.

Особенности и возможные проблемы:

- токсичные сообщения могут составлять небольшую долю от общего числа, что может потребовать применения методов снижения дисбаланса.
- сложные конструкции, сленг или опечатки могут повлиять на качество предсказаний.

Обоснование выбора:

- Датасет достаточно большой для обучения глубоких моделей.
- Реальная задача и разнообразие примеров повышают применимость модели в различных сценариях.

## Подход к моделированию

Для классификации будет использоваться облегчённая вариация модели BERT - DistilBERT от библиотеки Transformers Hugging Face, которая сохраняет высокую точность предсказаний при меньших вычислительных затратах. Реализация будет выполнена с использованием библиотек PyTorch и PyTorch Lightning.

1. Предобработка текста включает:
    - Удаление HTML-тегов, спецсимволов.
    - Токенизация.
2. Архитектура модели - DistilBERT с линейным классификатором на выходе.
3. Лосс-функция - Binary Cross-Entropy.
4. Обучение и валидация
    - Разделение данных на обучающую и валидационную выборки.
    - Использование ранней остановки, заморозки слоем и регуляризации.
5. Метрики: accuracy, F1-score

## Способ предсказания и финальное применение

После обучения модель будет обёрнута в продакшн-пайплайн, включающий следующие этапы:


1. Загрузка данных
2. Обработка входных данных:
    - Удаление HTML-тегов, спецсимволов.
    - Токенизация.
3. Загрузка обученной модели
4. Выполнение предсказаний.
5. Возможность дообучения модели на новых данных.
6. Логирование обучения и метрик качества.


## Схема пайплайна

- Загрузка датасета Kaggle и обновление данных при необходимости.
- Очистка и токенизация данных
- Обучение DistilBERT
- Сохранение весов модели.

## Используемые библиотеки и технологии

- PyTorch и PyTorch Lightning для разработки модели.
- Transformers от Hugging Face для работы с моделью DistilBERT.
- Kaggle для загрузки данных.
